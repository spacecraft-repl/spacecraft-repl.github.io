<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>SpaceCraft: A Real-Time, Collaborative REPL | Static webpage for SpaceCraft</title>
<meta name="generator" content="Jekyll v3.7.4" />
<meta property="og:title" content="SpaceCraft: A Real-Time, Collaborative REPL" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Static webpage for SpaceCraft" />
<meta property="og:description" content="Static webpage for SpaceCraft" />
<link rel="canonical" href="http://localhost:4000/whitepaper.html" />
<meta property="og:url" content="http://localhost:4000/whitepaper.html" />
<meta property="og:site_name" content="SpaceCraft: A Real-Time, Collaborative REPL" />
<script type="application/ld+json">
{"description":"Static webpage for SpaceCraft","@type":"WebPage","url":"http://localhost:4000/whitepaper.html","headline":"SpaceCraft: A Real-Time, Collaborative REPL","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="/assets/css/style.css?v=6d100b71fec1eb75369934e42a8a2e515bd2b9ad">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">SpaceCraft: A Real-Time, Collaborative REPL</h1>
      <h2 class="project-tagline">Static webpage for SpaceCraft</h2>
      
        <a href="http://github.com/spacecraft-repl/spacecraft-repl.github.io" class="btn">View on GitHub</a>
      
      
    </section>

    <section class="main-content">
      <!-- Insert SpaceCraft logo either above, below, or next to title -->
<h1 id="spacecraft-a-real-time-collaborative-repl">SpaceCraft: A Real-Time, Collaborative REPL</h1>

<h1 id="1-introduction">1 Introduction</h1>
<p>SpaceCraft is an open-source, real-time collaborative REPL (Read-Eval-Print-Loop) that allows users to write and execute code in the browser for Ruby, JavaScript, and Python. We built this project using Node.js and deployed via Docker, with the a client-server network architecture that communicates over WebSockets.</p>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vTnye5TTl38DZck_fV70plwTDrvrE5FfUqEO2kBCAvnb0fOOB9EGDcgRov10SZSdqLhJcZsA4TiCHHQ/pub?w=1440" alt="demo" /></p>

<p>SpaceCraft serves as a tool for developers to easily experiment with a programming language, while eliminating the burden of downloading and configuring the languages on their local machine. Furthermore, SpaceCraft makes pair-programming easy between interviewers and candidates, or with a small team of developers who want to share their experiences with a programming language.</p>

<p>The major challenges we faced were creating and managing server-side processes for executing code in the selected language runtime, allowing multiple clients to collaborate on the same REPL, and building a framework for security and resource usage with Docker containers.</p>

<p>In this case study, we’ll detail our journey in building this project, the strategies we employed to synchronize collaborating clients in real-time, the security techniques we implemented to prevent malicious code, and our network architecture. We’ll explore the choices we made to efficiently transfer user input and evaluated output between the clients and server, reduce our latency, and balance our resource usage across all our containers.</p>

<h2 id="11-high-level-goals">1.1 High-Level Goals</h2>
<p>SpaceCraft’s goals on the surface are simple. We aim to provide users with a choice of languages to code in and present both a terminal-like REPL and editor for them to write and evaluate their code. We also want users to be able to invite other users to join their session to collaborate on writing code in both the editor and REPL. This means that we will need to synchronize the displays among all collaborating users in real-time. When one user writes code or submits it for evaluation, all collaborating users should see the same state on their respective screens.</p>

<h2 id="12-challenges">1.2 Challenges</h2>
<p>In setting the above goals, we’ve introduced several challenges in our project that we will need to solve.
The biggest challenge is the security risk from providing users with a terminal-like REPL that directly connects to our back-end for code execution. This design opens the door for malicious code to be input by users directly into our system, making us vulnerable to a variety of exploits.</p>

<p>There also comes the challenge of spreading our resources across many sessions. There is the chance that one user’s code may require more resources than that of other users. If we don’t account for this, then we may have a single session hog resources away from other sessions and thus lower their performance.</p>

<p>So, we will need to:</p>
<ul>
  <li>Isolate each user’s session from the sessions of other users (non-collaborating users.)</li>
  <li>Prevent any malicious code from affecting our system.</li>
  <li>Manage the usage of our server’s resources for each session so that one user’s code doesn’t affect other users.</li>
</ul>

<p>In addition, we have the challenge of achieving high performance and low latency for the real-time code evaluation and display synchronization for our users. Since SpaceCraft aims to allow multiple users to collaborate and write code together in the same editor and REPL, we have to ensure that there is no noticeable lag in the synchronization of input and output, otherwise our users will have a frustrating experience working together.</p>

<p>These are a lot of challenges to solve, and we need to start somewhere. Let’s begin at a high-level with our network architecture, then step down one level to build our REPL and synchronize our input/output, and finish by drilling down into the details of handling the security and resource management of our project.</p>

<h1 id="2-network-architecture">2 Network Architecture</h1>
<p>In considering our network architecture, we need to make sure that our choice meets the following technical requirements:</p>
<ul>
  <li>Scalable: able to handle multiple language runtimes</li>
  <li>Supports 3-5 users per session for collaboration</li>
  <li>Detects when a client disconnects to free up resources for new users</li>
  <li>Allows bidirectional communication to handle high volumes of traffic from both clients and servers</li>
</ul>

<h2 id="21-client-server-architecture">2.1 Client-server Architecture</h2>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vQo6W0USG30ETbTw7ztlMQ7Z24iQp9dT1-65CyZXbJdvZWflNiRAedbbhJyeArL40YQ7TNbIoEwN5at/pub?w=1440" alt="client-server" /></p>

<p>We chose a client-server architecture in which users connect to a central server and start up a REPL session. Users who wish to collaborate can then connect to the same REPL session and have their input/output sync.</p>

<p>We initially started with using HTTP to have clients communicate with our server, but quickly discovered some issues with this approach:</p>
<ul>
  <li>There is no way for our server to automatically detect a client disconnection. The server would need to send an HTTP request to ping the client and determine if a disconnection has occurred.</li>
  <li>There is a significant amount of overhead (~200 bytes) with each HTTP request/response which adds up over time with multiple users collaborating in the same session.</li>
  <li>This overhead also adds up in the case of single users since our application sends a request to the server with each keypress as the user write code as part of our design to sync collaborating users.</li>
</ul>

<p>While it is possible to improve the above issues with HTTP server-sent events, it does not address the case where a client decides to send data frequently, for which regular HTTP requests have to be made. To fully address the problems mentioned above, we need an alternative that could provide bidirectional communication between a client and server, that could also detect client disconnections and have a smaller overhead. The best solution that we found was WebSockets.</p>

<h2 id="22-websockets">2.2 WebSockets</h2>
<p>We used the popular library <a href="https://socket.io/">Socket.io</a> to leverage WebSockets in SpaceCraft. The major benefit of using WebSockets is that it provides a bidirectional communication between the client and server over a single TCP connection. After an initial HTTP handshake to establish the TCP connection, our client and server will then be connected through WebSockets for further communication. This ensures that either the client or server can send information to the other when needed with an additional overhead of only ~10 bytes per message <sup><a href="http://www.diva-portal.se/smash/get/diva2:1133465/FULLTEXT01.pdf" title="Performance comparison of XHR polling,
Long polling, Server sent events and
Websockets by Rasmus Appelqvist,
Oliver Örnmyr">[1]</a></sup>. This is a ~95% decrease from using HTTP, and particularly useful in our case where we continuously stream data from the server to the clients.</p>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vQAdYwKH7kjzDDQv9GF-tpR9d2ZRK_vA661f2x3JPdTrPcE9c78WCl5rdyYW5XmyUy9wTYUlEZwQrEp/pub?w=1440" alt="http vs websockets" /></p>
<blockquote>
  <p>A full duplex persistent connection is possible with WebSockets. The connection stays open until either the client or server disconnects. Reference: <a href="https://www.ably.io/concepts/websockets">WebSockets - A Conceptual Deep-Dive</a></p>
</blockquote>

<p>Additionally, since the TCP connection over WebSockets remains open until either the client or server disconnects we can easily know when a user disconnects from out application. This enables us to efficiently begin the container teardown process and free up resources for new users. Finally, WebSockets allows us to maintain 1024 or more connections per server as opposed to ~6 connections per server with HTTP. This enables us to scale our application more efficiently as our user base grows.</p>

<h2 id="23-where-should-we-execute-the-code">2.3 Where Should We Execute the Code?</h2>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vSKVCKGZZHwgQFbXnMcyYpkhr4fJOUeeOxPp2zl1uLXM4nyxPOB7xT8gqMEkYZSlomKjDdk32voKaC6/pub?w=1440" alt="client-side server-side" /></p>

<p>Now that we’ve established our network architecture and communications, we need to decide where our code should be executed: on the client or on the server?</p>

<h3 id="231-executing-code-on-the-client-side">2.3.1 Executing code on the client-side</h3>
<p>Initially, we thought that we could execute on the client so that there is minimal latency between the user submitting code for evaluation and then receiving the result. Additionally, we could set-up a peer-to-peer architecture for collaborating users to sync input/output.</p>

<p>However, there are several problems with this approach. First, we face the burden of running an in-browser compiler, which can be slow and even cause the browser to hang. Second, this is not scalable because we would be relying on the client’s computer resources for handling and running the language runtimes.</p>

<p>The storage requirement for each language ends up being ~50MB, and thus as we continue to support more languages in the future we would be expecting the client to handle increasing memory usage.</p>

<p>Finally, not all languages come with an in-browser compiler and thus we would need to figure out a way to compile these language runtimes into JavaScript ourselves.</p>

<p>Vincent Woo, Founder of Coderpad.io, in one of his <a href="http://codeinsider.us/i/5.html">interviews</a> mentioned:</p>
<blockquote>
  <p>“One day I sucked it up and I just realized that there was no way I could scale this completely in-browser execution out as far as I needed it to… What are you going to do, compile every programming runtime into JavaScript? Good luck.”</p>
</blockquote>

<h3 id="232-solution-executing-code-on-the-server-side">2.3.2 Solution: Executing code on the server-side</h3>
<p>For all these reasons, we will need to execute our code on the server-side. This ends up making it easier to manage multiple runtimes and easier to scale since we can upgrade our server resources and have our memory and CPU more readily available than a client’s. Furthermore, by relying on a central server, we can more easily handle conflicts due to concurrent edits.</p>

<p>The tradeoff is that we will need to efficiently manager our server resources, along with facing increased latency and server costs. However, we feel that these tradeoffs are acceptable in order to meet our goals.</p>

<h1 id="3-building-a-repl">3 Building a REPL</h1>
<p>Now that we’ve designed our architecture, our next task is to create a version of SpaceCraft that services a single user per session. Once that’s complete, we can add mult-user collaboration. For now, we need to allow the user to:</p>
<ul>
  <li>Select from a list of supported languages.</li>
  <li>Write code in the REPL, submit for evaluation by hitting Enter, and receive the result as output.</li>
  <li>Write code in the editor, submit for evaluation by clicking a Run button, and receive the result as output.</li>
  <li>Store state in the client, such as the current line of input for evaluation and the current language for UI display.</li>
</ul>

<p>In SpaceCraft, a user makes a language selection from a drop-down menu which will automatically update the REPL to their chosen language runtime. They can then write code directly into the REPL for evaluation or into an embedded editor for writing larger programs.</p>

<p>When code is submitted for evaluation, our app will take the code as input and send it to our server for evaluation. Once this is complete, our server will send the result as output to the client, which is displayed in the user’s REPL.</p>

<h2 id="31-creating-the-user-interface">3.1 Creating the User Interface</h2>
<p>SpaceCraft’s user interface is created with <a href="https://github.com/xtermjs/xterm.js/">Xterm.js</a> and <a href="https://codemirror.net/">CodeMirror</a>. Xterm is a terminal front-end component written in JavaScript that creates an emulated terminal for our REPL in which users can write their code and submit for evaluation. When a user hits Enter in the RPL, their code is sent as input to our server for evaluation, and the result is then sent back to be displayed in the REPL.</p>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vT218z12UgSMqH_Yqbn-d-ZqFIhVvESDv5-8HeZebQsOoRhCxK6bjw7OYP0a9fiQWPzhiVBSWMob0l6/pub?w=1440" alt="front-end UI" /></p>

<p>CodeMirror is a versatile text editor implemented in JavaScript for the browser. It’s specialized for writing and editing code and provides a familiar text editor experiences for developers. By leveraging Xterm.js and CodeMirror to create our user interface and receive input, our team was able to focus our efforts on developing a rich REPL experience for Ruby, JavaScript, and Python, along with a secure framework for handling malicious user input. So now we need to figure out how to handle a user’s input and properly evaluate it on our backend.</p>

<h2 id="32-interacting-with-the-repl-program-on-the-back-end">3.2 Interacting with the REPL program on the Back-end</h2>
<p>Since we want provide users with the ability to submit code remotely for server-side evaluation, we have to simulate the entire interaction with the REPL program ourselves. This is fundamentally different from the regular experience with a REPL program in which a user directly inputs code into an interactive REPL console like <em>irb</em> or <em>node</em>.</p>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vQOAjlP1_EdFI1Jk_8rRaA_ExbLCtqczdL6rsAXwedI7OnYP4ovCn1Z12BXkEYk4UOa-Cy3aU3ue0sb/pub?w=1440" alt="local interaction" /></p>
<blockquote>
  <p>A regular interaction between a user and a REPL program via a terminal</p>
</blockquote>

<p>For our project, the interaction between the user and the underlying REPL program will have to be manually set-up through our application logic. Our application must be able to send inputs to the REPL program on the back-end and read any outputs after an evaluation is completed. This means that we have to also consider the complexity that comes with interacting with REPLs of different languages.</p>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vQ6MwTViENag3nS5sQ-cyiwE4lQbTO-oa8Dc5SMNRjqpDTejskWvnHRZOFTpp_whkr15GmjpjQ0gkX3/pub?w=1440" alt="simulated interaction" /></p>
<blockquote>
  <p>Our application has to properly write inputs to the underlying REPL program and read outputs from it</p>
</blockquote>

<p>With this challenge in mind, we will explore three different approaches that can help set up our interaction with the REPL program.</p>

<h3 id="approach-1-interact-with-the-languages-built-in-repl-api-library">Approach #1: Interact with the language’s built-in REPL API library</h3>
<p>Many languages provide APIs to access and interact with its native REPL program. Node.js for example, provides the <code class="highlighter-rouge">repl</code> module that allows developers to work directly with its API from within the application code.</p>

<p>The problem with using language-specific APIs, however, is that we would have to write and run the application code in that language runtime. For each additional language supported, we would need to rewrite the same logic in that language. The complexity increases exponentially with each additional supported language.</p>

<p>Thus, our goal of supporting three languages, and potentially more in the future, does not benefit from this approach.</p>

<h3 id="approach-2-spawning-a-repl-child-process-and-interacting-directly-with-it">Approach #2: Spawning a REPL Child Process and Interacting Directly with It</h3>
<p>We could also make use of APIs that enable us to access the standard streams of a REPL child process. In particular, we are going to access the standard input (a writable stream) as well as the standard output (a readable stream) of the REPL child process. More info on working with streams can be found here: <a href="https://medium.freecodecamp.org/node-js-streams-everything-you-need-to-know-c9141306be93#4fc8">Node.js Streams</a>.</p>

<p>We can naively think that writing into the standard input would produce a desired output, however the output may hang. This can be seen in the gif below in which we are accessing the standard streams of a REPL process:</p>

<p><img src="https://i.imgur.com/apJCqSf.gif" alt="shell-test-demo" /></p>

<blockquote>
  <p><em>Notice that the output hangs while <code class="highlighter-rouge">stdin</code> is left open</em>
<em>IRB produces a full output, while Node.js and Python do not</em></p>
</blockquote>

<p>There are two possible reasons as to why this may occur.</p>

<p>First, streams may be blocked when we try to read from the standard output. One problem is that the standard input may not send any data to the REPL process for evaluation until the input stream is closed. <sup><a href="https://stackoverflow.com/questions/9818534/why-is-it-necessary-to-close-standard-input-output-error-when-writing-a-daemon" title="Stack Overflow: 'Why is it necessary to close standard input/output/error when writing a daemon?'">[1]</a></sup></p>

<p>Second, interpreted languages are usually written in lower-level languages, and due to how the language interacts with the standard stream, it may be a cause of hanging outputs. For example, the C implementation of <code class="highlighter-rouge">read()</code> <a href="https://linux.die.net/man/3/read">function</a> would hang when we try to read from an output stream, until new data is being written to the corresponding input stream.</p>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vR4hvoZaifOI5Xh_BkDWiGcKP28pu8DCevtEJKMsi08O0fIaNozngsKoWNItFskmBjBMN8OURK9oOpP/pub?w=1440" alt="streams blocking" /></p>

<p>Although there are <a href="http://eyalarubas.com/python-subproc-nonblock.html">techniques</a> to unblock the processes for reading or writing from the streams, the techniques are not universal on all languages. If we were to implement various techniques to get around this issue, our application’s code complexity would increase significantly. Thus, this approach does not fit our use case.</p>

<h3 id="approach-3-interacting-with-a-pseudoterminal">Approach #3 Interacting with a Pseudoterminal</h3>
<p>The solution that we found to overcome this challenge is through the use of pseudoterminals. The basis of this approach is that REPL programs are inherently terminal-oriented programs, which means that they expect to connect and work with a terminal. The fundamental problem that we are trying to address here becomes:</p>

<p><strong>How can we enable a user to interact with a terminal-oriented program on a remote host?</strong></p>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vSiAyIrp0gxipR4IAwjRFzwHDuBIMhNoM8Vzz9zEF2J0CsRviYUNhxP0kID5V-05NGp0cwsx6ZxP8Ik/pub?w=1440" alt="remote interaction ?" /></p>
<blockquote>
  <p>Providing communication over a network solves part of the problem, but it does not address the connection of standard input, output and error to a terminal-oriented program</p>
</blockquote>

<p>A terminal-oriented program expects a terminal to perform certain kinds of processing of its inputs and outputs. This is useful to prevent the default blocking of buffering during reads and writes from our application. The additional processing will also allow the generation of terminal-related signals (such as SIGINT) onto the program.<sup><a href="https://nostarch.com/tlpi" title="The Linux Programming Interface, Chapter 64, pages 1375-1377">[1]</a></sup> In other words, the terminal appropriately translates inputs and outputs between our application and the REPL program.</p>

<p>A pseudoterminal provides this missing piece, which is a terminal device that connects to our REPL program. In doing so, it acts a communication channel between our application code and the underlying REPL program so that they may be able to speak to each other.</p>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vSHn46g_dV1eF_O5RU1fCG1jXXCU0JuJLf0qtigaZGKGrynvv9meoI7Rism-0qfwNLU52JUSn4wjGU9/pub?w=1440" alt="pseudo-terminal remote interaction" /></p>
<blockquote>
  <p>Connecting the pseudoterminal with our application server and our REPL program solves the communication issues mentioned previously</p>
</blockquote>

<p>This is useful since we can easily persuade our REPL program that its input is coming from a terminal, and thus allow us to gain the benefits of:</p>
<ul>
  <li>offloading the burden of managing input and output streams of different REPL runtimes</li>
  <li>allowing sending of control sequences (such as Ctrl-C) to the REPL, effectively sending an interrupt signal to the runtime</li>
  <li>capturing full outputs from the REPL program, including colored outputs</li>
  <li>standardizing the way our application interacts with the different REPLs of supported languages, thereby increasing extensibility for adding more languages in the future</li>
</ul>

<p>To demonstrate the advantages mentioned above, we have also made a recording of a coding example that illustrates the interaction with a pseudoterminal through the use of <code class="highlighter-rouge">node-pty</code> library:</p>

<p><img src="https://i.imgur.com/NZSzm7T.gif" alt="pty-demo" /></p>
<blockquote>
  <p><em>Notice that REPLs produce full outputs regardless of chosen runtime. Prompts and color outputs are also displayed.</em></p>
</blockquote>

<p>With these advantages mentioned, we can further reduce our code complexity since pseudoterminals provide a standardized way of handling inputs and outputs.</p>

<p>The trade-off of using a pseudoterminal is that there is a slight increase in overhead as we are adding an additional processing layer in between our application and the underlying REPL program. However, with all the benefits mentioned, this approach fits our use case.</p>

<h1 id="4-collaboration-with-multiple-users">4 Collaboration with Multiple Users</h1>
<p>Now that we have built our REPL on the back-end, we need a way to synchronize the input and output of a session across collaborating users. This synchronization needs to occur for both the REPL and text editor components of the front-end.</p>

<p>We’ll first handle the REPL synchronization, for which there are two main components: the current line of REPL input and the result of code evaluation as output.While it is possible to utilize external libraries to manage the synchronization of REPL inputs and outputs for us, we chose to build this feature ourselves from scratch. Our reasoning is so that we can:</p>
<ul>
  <li>easily add new features that are not supported from the library, such as handling output overflow during an infinite loop</li>
  <li>control the flow of data (streaming vs. buffering data chunks) so that we can more easily optimize the flow of input/outputs to reduce latency</li>
</ul>

<h2 id="41-syncing-output">4.1 Syncing Output</h2>
<p>To synchronize outputs, our application server broadcasts the evaluation outputs to currently connected clients. The flow of output synchronization is as follows:</p>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vQpdFdytJndBFsKwvJTqgLZd6UhIe7dEY27olnXjDX5lo8BXocZN3xA1zbXFZMVkCW4m7h1h3kmOt3V/pub?w=1440" alt="output sync evaluation" /></p>
<ol>
  <li>Client requests a line of code to be evaluated</li>
  <li>Application server receives line of code</li>
  <li>Application server sends the line of code to the pseudoterminal that is connected to the REPL program.</li>
  <li>The REPL program evaluates the line of code and sends the appropriate output data to the pseudoterminal.</li>
  <li>Application server reads the evaluation outputs from the pseudoterminal.</li>
</ol>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vT1eaaey9-P8vNXGVRrCeTvEr1lMDlr8OrHSZZAHfjNMT9mb3CfQtCqR7neKcKu-nXjqAN0A3R5SBgQ/pub?w=1440" alt="output sync broadcast" /></p>

<ol>
  <li>Application server broadcasts and streams the outputs to all connected clients.</li>
  <li>Clients receive the outputs and display them on the front-end terminal.</li>
</ol>

<h2 id="42-syncing-input">4.2 Syncing Input</h2>
<p>Since we are building our input synchronization feature from scratch, we need to manually handle the current line of input. We chose to track the current line of input on the client-side so that local edits can be updated and displayed immediately. With this approach however, there is a possibility that conflicts will occur if two clients happened to edit their inputs at the same time. Nonetheless, this is generally not an issue for our use case, as we’ll explore more in the following section.</p>

<p>Our input-syncing mechanism consists of the following steps:</p>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vT7AnhrTSfePigTwPc-Igul7a6A9k3fkygmmfoGylp85kB_BNDc2AKKv8qNPZJrs68VcHa3KM6ooAnK/pub?w=1172&amp;h=621" alt="input sync 1" /></p>

<ol>
  <li>The state of the input line before any changes.</li>
  <li>The user presses a key on the REPL front-end terminal. The state is updated in the user’s client.</li>
  <li>The user’s client sends a message with the current input line to inform the application server that the current line has been changed.</li>
</ol>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vTbNvqeH7bv8wC0VfljTRm3PSQxhyRBvdKdaQlcpR-PpHeiIpyYiOiUH9UINaafsSfpiJwM3LcH9cFH/pub?w=1305&amp;h=624" alt="input sync broadcast" /></p>

<ol>
  <li>
    <p>Our application server broadcasts a message that includes the current line and prompt to other clients. The prompt is retrieved from the most recent output cache. It is used to rewrite the entire terminal line in the following step.</p>
  </li>
  <li>
    <p>When other clients receive the message, their local states are updated to include the current line of input.</p>
  </li>
  <li>
    <p>The client updates its UI by first clearing the last line of the terminal. Since the prompt is also erased, it has to rewrite the prompt before writing the current input line.</p>
  </li>
</ol>

<h2 id="43-handling-conflicts-in-shared-editing">4.3 Handling Conflicts in Shared Editing</h2>
<p>Giving users the option to collaborate in real-time means that potential conflicts can occur if multiple users type at the same time. This may occur if our server receives updates in a different order than they were sent due to one client being closer to the server than another. When conflicts happen, both clients <a href="https://conclave-team.github.io/conclave-site/#what-is-a-real-time-collaborative-text-editor]">may not converge</a> to the same state.</p>

<p>For example, when a user inserts a character at position index 0 and another user deletes at the same position, and both operations happen at the same time, we need to resolve any conflicts so that both clients will arrive at the same state.</p>

<h3 id="431-conflict-resolution-in-repl-terminal">4.3.1 Conflict Resolution in REPL terminal</h3>
<p>In our REPL terminal, we will rely on <a href="https://en.wikipedia.org/wiki/Eventual_consistency">eventual consistency</a> to resolve conflicts. This means that if both clients happen to type on the REPL terminal at the same time, the last update that is received by our application will take precedence. This is also known as “last write wins”.</p>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vQWK_l-v1bmvCcqjVJNHi1StdP7avDVq833bcppB_FXXAYJ84ilmOzXLs4HBsCIaas5EiPYvbij79X3/pub?w=1302&amp;h=690" alt="last write wins" /></p>

<ol>
  <li>Both users in client A and B edit at the same time. Client A’s update will arrive first due to a lower latency than client B’s</li>
  <li>Since client B’s update is received last, it takes precedence and overwrites the previous update.</li>
  <li>Our application server broadcasts the last update to the other clients.</li>
</ol>

<p>We chose not to employ any Operational Transformation or Conflict-free Replicated Data Type (CRDT) techniques for resolving potential conflicts in our REPL terminal input, due to unnecessary code complexity as well as additional server overhead. Our reasoning is that we expect users to take turns instead of competing against each other when evaluating inputs in our REPL.</p>

<h3 id="432-conflict-resolution-in-text-editor">4.3.2 Conflict Resolution in Text Editor</h3>
<p>Now that we’ve handled the REPL input and output synchronization, let’s turn to the text editor. The text editor component will allow multiple users to write code at the same time. We can expect there to be a higher likelihood that a conflict will occur in the editor because most people will write their code in the editor and then submit for evaluation. We can reasonably expect that both users will type at the same time, and if they happen to type into each other’s code by accident, we would like to make sure that:</p>
<ul>
  <li>concurrent insertion converge to the same result, regardless of order in which they are applied</li>
  <li>duplicated delete operations are only applied once to produce the same result</li>
</ul>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vQkm0mEhBrkFW1rqPl6ZAu7UJCQ_5Q0IUazA5lxt3JtZxWDCJgbhUHB1OVr_dh_3LLxAMlFeUPG29p2/pub?w=1305&amp;h=594" alt="conflict in concurrent edit" /></p>
<blockquote>
  <p>Simultaneous insertion and deletion produce different results. Source: <a href="https://conclave-team.github.io/conclave-site/">Conclave: A Real-Time Collaborative Text Editor</a></p>
</blockquote>

<p>To solve this issue, we utilized <a href="https://github.com/y-js/yjs">Yjs</a>, a shared editing framework that utilizes Conflict-Free Replicated Data Type (CRDT) for conflict resolution. We also chose Yjs because of its WebSockets adapter that integrates nicely into our application.</p>

<p>However, the trade-off of utilizing Yjs is that it increases memory consumption on the server-side. This is likely due to the caching of replicated data structures that are required for CRDTs to work. Nonetheless, we chose to use it since it provides a low-latency and conflict-free collaborative environment for our users.</p>

<h1 id="5-security--resource-management-with-containers">5 Security &amp; Resource Management with Containers</h1>
<p>At this point, we’ve succeeded in taking a user’s code and evaluating it in a language runtime while also synchronizing displays across collaborating users. Now, we need to consider the security and resource management challenges mentioned at the start of this case study.</p>

<p>Since we are connecting users with a pseudoterminal that allows execution of user input on our server, we leave ourselves and our users open to the risk of any malicious code submitted directly into our backend. We will need to think of a way to protect both ourselves and our users.</p>

<h2 id="51-naive-approach-check-user-input-against-list">5.1 Naive Approach: Check User Input Against List</h2>
<p>Our initial idea was to run a check on all user input against a list of possibly malicious commands. For example, let’s say a user attempts to submit a command like <code class="highlighter-rouge">system rm -rf /</code> into the Ruby REPL. We can check their input against a list of Linux commands and match <code class="highlighter-rouge">rm -rf /</code> which would lead our system to halting the execution of this input.</p>

<p>While this sounds like a straightforward solution, it’s hindered by the fact that we would need to consider and plan for all possible inputs that could be malicious. This is an enormous task that would require a significant amount of research to make sure that we don’t miss every possibility, and is compounded by any language-specific inputs for our supported languages. It also addes an additional processing step to our application logic which would negatively impact our user’s experienced latency.</p>

<h2 id="52-solution-isolation-via-containers">5.2 Solution: Isolation via Containers</h2>

<p>Instead, we can isolate each user’s session, and thereby isolate their code, within our application. This will help contain any malicious code away from our host system and other users. With this isolation comes several challenges:</p>
<ul>
  <li>How do we provide each user with an isolated, complete copy of our application to evaluate their code?</li>
  <li>How do we handle any malicious code submitted by the user, which may be able to break out of isolation?</li>
  <li>How do we manage our backend computing resources for isolated user so that one user’s code evaluation doesn’t rob resources from another user?</li>
  <li>How do we enable multiple users to collaborate in the same isolated environment?</li>
</ul>

<p>We chose to implement containers to address these challenges. Through containers, we are able to provide an isolated, complete copy of our application for each user. We can effectively separate users from each other, easily add layers of security to contain malicious code, and ensure that one container only uses a set amount of resources. Let’s start with how we can segment users by container.</p>

<h2 id="53-segmenting-users-by-container">5.3 Segmenting Users by Container</h2>
<p>The core idea behind containers is that you create a single unit of software that is encapsulated and can be deployed anywhere. By putting your software and dependencies in a container and operating within in, we can effectively deploy our container on any system without worrying about the host system configurations. In addition, containers provide a level of isolation from the rest of the system that enable security measures to be placed to prevent the software in a container from affecting the rest of the system and other users’ sessions.</p>

<!-- Docker logo -->

<p>To start, we used Docker to create our containers which will each hold an entire copy of our application code. Containers are created using an image, which provides the details of all the software and dependencies that should be included in the container. Once we need to instantiate a new container, we simply execute a run command that instantiates a container using the image as a blueprint.</p>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vRGOfNrPPMkt8RdA_USJSal6Kcatzr9TmoH9zjjSybDbygU6HizCDJraLG358rO84oplyJPwrJug5wM/pub?w=1305&amp;h=674" alt="docker image" /></p>

<p>Thus, our new user workflow is as follows:</p>
<ol>
  <li>a new user makes a request to our application.</li>
  <li>when our server receives the request, a new container is created based on an image that contains our application, required dependencies and operating system.</li>
  <li>the server then redirects the user’s request to the container.</li>
  <li>the user then establishes an active connection with container which serves as their session and they can begin coding away with our REPL.</li>
</ol>

<p>With this design, each user is given their own isolated environment to write and evaluate their code. If any user attempts to submit malicious code to destroy our application, they will only be affecting their copy of our application code within the container and our host system is unaffected.</p>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vRtVA-YL9rfCMfvPq6Wm5uOFp611rGOf0KscBC38Q-KjnNnebUiwgRSa7XSTeQ_g9LX7r9nJ-SPH3MY/pub?w=1440&amp;h=740" alt="isolated attack" /></p>
<blockquote>
  <p>When a container is compromised due to a malicious attack only the session that is associated with the container will be affected.</p>
</blockquote>

<p>However, this is only a start as there are ways for users to break out of their containers and we need to add some more security measures. Also, at this point each container can draw upon all of the host server’s resources to evaluate the user’s code. This is not ideal since one user’s code could be more computationally intensive and consume more CPU and memory resources away from other users, thereby worsening their session’s performance. Let’s see how we can fix this!</p>

<h2 id="54-securing-containers">5.4 Securing Containers</h2>
<p>The main issue of security within containers is when users are given root access, which is actually the default setting with Docker. This allows users to have complete access to the files within the container and the ability to do some truly malicious activity.</p>

<h3 id="541-remove-root-level-access">5.4.1 Remove Root-level Access</h3>
<p>The first step to securing our container is to remove the default root-level access and prevent users from being able to execute harmful commands such as <code class="highlighter-rouge">rm -rf /</code> in our application.</p>

<p>To achieve this, we can simply create a user with restricted permissions that will run as the default profile for any user in our container. The restrictions include making them a non-root user and creating a special <code class="highlighter-rouge">bin</code> folder from which they access their terminal commands. This special <code class="highlighter-rouge">bin</code> folder will have a limited number of commands for use and will not include commands such as <code class="highlighter-rouge">touch</code>, <code class="highlighter-rouge">mkdir</code>, <code class="highlighter-rouge">rm</code>, and so on.</p>

<h3 id="542-strengthen-isolation-with-container-runtime-sandbox">5.4.2 Strengthen Isolation with Container Runtime Sandbox</h3>
<p>While containers provide some isolation between our host system and application, containers <a href="https://cloud.google.com/blog/products/gcp/open-sourcing-gvisor-a-sandboxed-container-runtime">are not inherently a sandbox</a>. Applications that run in containers access system resources in the same way that non-containerized applications do, which is by making privileged system calls directly to the host kernel. What this means is that container escape is still possible with a successful privilege escalation attack. An example would be the <a href="https://en.wikipedia.org/wiki/Dirty_COW">Dirty Cow</a> (copy-on-write) vulnerability that gives attackers write access to a read-only file, essentially giving them access to root.</p>

<blockquote>
  <p>Our current container architecture. Docker alone provides weak isolation, where all system calls made by our application are accepted by the host kernel</p>
</blockquote>

<p><img src="https://i.imgur.com/QdXUTH3.png" alt="weak isolation" /></p>

<p>While we can run containers within a virtual machine to provide strong isolation from the host system, it also means a larger resource footprint (gigabytes of disk space) and slower start-up times.</p>

<p>A container runtime sandbox provides similar level of isolation with virtual machines while minimizing resource footprint. A runtime sandbox achieves this by intercepting application system calls and acts as the guest kernel. On top of that, it also employs rule-based execution to limit the application’s access of resources. With this, any attempted privilege system calls will be intercepted, before it has a chance to reach our host system.</p>

<p>We chose to leverage gVisor, an open-sourced container runtime sandbox developed by Google, because it provides the security benefits mentioned above and integrates well with Docker.</p>

<blockquote>
  <p>Unprivileged access is enforced through the use of a container sandbox runtime, which provides a much stronger isolation between our application and the host kernel</p>
</blockquote>

<p><img src="https://i.imgur.com/3PUBSki.png" alt="givsor strong isolation" /></p>

<p>The trade-offs of using such a container runtime sandbox however, are reduced application compatibility and a higher per-system call overhead. Nevertheless, our application functions properly and there is no noticeable difference in performance even with gVisor enabled. Thus, using gVisor fits our use case.</p>

<p>With these measures in place, we have effectively made a user profile that is incapable of accessing or changing the files in the container, along with making it a lot harder for users to submit malicious code.</p>

<h2 id="55-managing-container-resources">5.5 Managing Container Resources</h2>
<p>Now that we’ve tackled the security issues of using containers, we need to turn our attention to managing the container’s resources. By default, each container is able to consume the entire CPU and memory of their host server to complete their processes. While this makes sense at a high level as you want each container to have sufficient resources to complete their work, it becomes a liability when a user submits code for evaluation that is computationally intensive.</p>

<p>For example, a user in one container may write a program that requires a large amount of mathematical calculations, string processing, or infinite loops that cause a spike in CPU usage which causes a drop in performance for other containers. Or a user may input large amounts of data into the text editor that eat away at the available memory in our host server and leave little remaining for other users. To combat these issues and ensure that each container only uses a reasonable amount of resources, we can use Docker’s cgroups (control groups) to place a resource limit on each container.</p>

<p>At its core, a cgroup is simply a limitation placed on an application or container to a specific set of resources. By specifying this limitation when creating a container, we can easily set the max CPU or memory allowed for use by a container. So if we want to spin up a container that can only use 20% of our total CPU and 100MBs of our total memory, all we need to do is include ` –memory=100m -it –cpus=”.2”<code class="highlighter-rouge"> within our </code>docker run` command. And just like that, we’ve handled any potential hogging of resources by a single container and ensured stable performance across the board for our users.</p>

<h1 id="6-connecting-users-to-containers">6 Connecting Users to Containers</h1>
<p>At this point, we’ve successfully built our collaborative REPL and isolated complete instances of our application in containers. Now, we need to evaluate how we can connect clients to their associated container on the server, as well as allowing a user to invite other users to collaborate in their session.</p>

<h2 id="61-naive-approach-port-forwarding">6.1 Naive Approach: Port Forwarding</h2>
<p>Each container will have a unique IP address and port number associated with it, and the question becomes how we can route a user’s request for a session to a container and form a connection. We first considered using port forwarding, which takes the initial HTTP request from the client and forwards it to the address and port number of a ready-to-use container.</p>

<p>This technique is simple since it’s a direct mapping of a client to a container destination. However, this technique is flawed by being a security risk since the port numbers are pre-determined. By running a port scanner to probe for open ports, a user could potentially access any session. This leads to a complete lack of privacy for our users who wish to collaborate only with the people they invite to join their session.</p>

<p>We need a better approach that can protect our users’ privacy and mask the connections to our containers. Thankfully, this can be achieved with a reverse proxy.</p>

<h2 id="62-solution-a-reverse-proxy">6.2 Solution: A Reverse Proxy</h2>
<p>The idea behind a reverse proxy is that there is some middleware that sits between our clients and our server which serves as an intermediary between the two. When a client sends an HTTP request to our server, a reverse proxy will receive that request and communicate with our server for the necessary information. The server will respond to the reverse proxy with the container’s IP address and port number, which will then take that information and forward the client’s request to that container for connection. Thus, our reverse proxy will handle all the traffic between our clients and server.</p>

<p><img src="https://imgur.com/eIBtN6g.png" alt="reverse proxy" /></p>

<p>While this may sound like a roundabout way of handling a request and response, the benefit is that we can abstract away the connection of addresses and ports to ensure the privacy of our sessions. From the client’s perspective, they are connected to the appropriate container and don’t know the exact IP address or port number of the container or our host system.</p>

<p>Furthermore, our proxy server can assign random URLs to created sessions, thereby preventing other unwanted users from gaining access to a current session through port sniffing or guessing pre-determined URLs. We will detail how this works in the following section.</p>

<p>In our application, the reverse proxy will handle the initial HTTP handshake that is needed to connect a client with a container for their session. Once this handshake is complete, a WebSockets connection is created between the client and container that will persist for the remainder of the session until all connected clients disconnect.</p>

<p><img src="https://i.imgur.com/rjdOm1W.png" alt="websockets" /></p>

<p>Along with solving our privacy concerns, a reverse proxy provides our application with greater scalability as our user base grows. It can serve as a load balancer as we add more servers and it can provide content caching to reduce latency for particular content outside of establishing the client-container connection.</p>

<h2 id="63-session-management">6.3 Session Management</h2>
<p>In order to connect different groups of users to different sessions, our reverse proxy server is also responsible for:</p>
<ul>
  <li>initializing a session within a new container</li>
  <li>forwarding requests to the appropriate container</li>
  <li>destroying a session and it’s container</li>
</ul>

<p>In order to customize a reverse proxy to fit our use case, we built our reverse proxy from scratch using mostly VanillaJS, aside from using a few essential libraries to help us get started.</p>

<h3 id="631-session-initialization">6.3.1 Session Initialization</h3>
<p>To initialize a session, we need to:</p>
<ol>
  <li>generate a unique URL for every session we create</li>
  <li>instantiate a container to start an instance of our application</li>
  <li>map the generated URL to the newly created container’s private IP and port number</li>
</ol>

<h4 id="6311-generating-unique-url">6.3.1.1 Generating Unique URL</h4>
<p>The basic idea behind preventing users from being able to guess a URL is by randomizing it with a sufficiently large number generator. For this, we utilized a UUID generator to generate our session ID. At our current scale, the first 6 digits of the UUID is sufficient, as it already provides 16,777,216 possibilities.</p>

<h4 id="6312-path-based-url-forwarding">6.3.1.2 Path-based URL forwarding</h4>

<p>Our initial approach is to attach the generated session ID to the path of the URL. For example, we assign a session ID of <code class="highlighter-rouge">123456</code> to the URL <code class="highlighter-rouge">spacecraft-repl.com/123456</code>. With this, every session can be identified by their path name. However, the problem is that assets like JavaScript or CSS files that are requested via the root path will not automatically receive the session ID as part of its path name. For instance, a client’s request to fetch <code class="highlighter-rouge">/main.js</code> will not contain the session ID, and since it does not match <code class="highlighter-rouge">/123456</code>, the request will fail.</p>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vSXRH02roO9RBQITOtlheiN8qaanmQx-IPmv6ThmfzAB6-eRcTPobjm0UGARUUORfb27TdBeXcKYf78/pub?w=1440&amp;h=810" alt="path forwarding" /></p>
<blockquote>
  <p>An absence of session ID following the root path leads to confusion in our reverse proxy</p>
</blockquote>

<p>There are certainly ways to get around this issue. The first solution is to add some client-side logic to modify requests to include the session ID. For example, changing the request of <code class="highlighter-rouge">/main.js</code> to <code class="highlighter-rouge">/123456/main.js</code> enables our reverse proxy to capture the session ID and to forward it accordingly. The second solution is to read the <code class="highlighter-rouge">Referer</code> header of each request to obtain the previous URL that includes the session ID. With the session ID obtained, our reverse proxy server can forward the request to its destination container.</p>

<p>However, we chose not to go with this approach as it leads to unnecessary complexity in the client-side code. Furthermore, the <code class="highlighter-rouge">Referer</code> header may not always give us the expected URL that contains the session ID, particularly when working with Socket.io. Since directly solving these problems require some degree of request manipulation, we opt for the approach of subdomain forwarding due to its simplicity.</p>

<h4 id="6313-subdomain-forwarding">6.3.1.3 Subdomain forwarding</h4>
<p>To get around this issue, we decide to work with subdomains instead. Essentially, the session ID will be a part of the hostname instead of the path. For instance, a session ID of <code class="highlighter-rouge">123456</code> forms a subdomain URL of <code class="highlighter-rouge">123456.spacecraft-repl.com</code>. This ensures that the session ID can be read from the hostname, preventing any path changes from confusing our reverse proxy server like <code class="highlighter-rouge">123456.spacecraft-repl.com/main.js</code>.</p>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vTcPVwBQa001D2GXjI30Xf0J5I9lTFS5_-i3wjumIieVXpWjwC6u8Qt_3zA6eDJufH00NCk3jyOUMGz/pub?w=1440&amp;h=810" alt="subdomain forwarding" /></p>
<blockquote>
  <p>With subdomains, the session ID is always read from the hostname, and it is never lost even if the path changes</p>
</blockquote>

<p>The trade-off with using subdomains is that it may potentially be confusing to users, since subdomains are generally used to create different sites using the same domain name.</p>

<h4 id="6314-url-mapping-to-designated-container">6.3.1.4 URL Mapping to Designated Container</h4>
<p>With our URL generated, we can then map the URL to a designated container via its private IP address and port number. The flow of events are as follows:</p>
<ol>
  <li>A container is created (with our application running)</li>
  <li>The URL is saved as a key in the hash table</li>
  <li>The container’s IP address and ID are saved as an object. The object is then assigned as the corresponding property value.</li>
</ol>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">sessions</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">'123456.spacecraft-repl.com'</span><span class="p">:</span> <span class="p">{</span>
    <span class="na">ip</span><span class="p">:</span> <span class="s1">'172.17.0.2:3000'</span><span class="p">,</span>
    <span class="na">containerId</span><span class="p">:</span> <span class="s1">'a9405c025dc4...'</span>
  <span class="p">},</span>
  <span class="s1">'abc123.spacecraft-repl.com'</span><span class="p">:</span> <span class="p">{</span>
    <span class="na">ip</span><span class="p">:</span> <span class="s1">'172.17.0.3:3000'</span><span class="p">,</span>
    <span class="na">containerId</span><span class="p">:</span> <span class="s1">'...'</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<ol>
  <li>With the hash table in place, we can retrieve the designated container’s IP in O(1) time given the hostname of a request.</li>
</ol>

<h3 id="632-destroying-a-session">6.3.2 Destroying a Session</h3>
<p>With our session initialization process complete, we now need to consider the session teardown process. Once all clients have left a session, we want to start breaking down the remaining container so that we can free up the allocated resources for new sessions. This is preferred over connecting new users to a used container since there may be some remaining artifacts leftover in the session from the previous users, and we instead want to present a clean slate for new users.</p>

<p>To initiate the tear down process, we need to determine if an application instance has no clients connected to it. We can easily tell if a client has disconnected from a session with WebSockets since Socket.io provides a disconnect event that fires upon client disconnection. But what happens if a client leaves their session before completing their connection to a container, like in the case of closing their browser early?</p>

<p>To handle this case, we can check whether there are any connected clients to a container after a certain timeout. While it is easy to detect that within our application server, how do we notify our reverse proxy server? To do this, we’ll have our application server communicate with our reverse proxy through HTTP requests. The diagram below illustrates the flow of events during a teardown.</p>

<p><img src="https://docs.google.com/drawings/d/e/2PACX-1vTHvG1C5YQke_0kwYAKCy3nVea_iqqXv5uXVh9bWTQgMqfQzhwoLj4yUS3RIIlFMf6i2E9MhqLXOIkw/pub?w=1440&amp;h=810" alt="destroy session" /></p>

<ol>
  <li>A session is initialized with a running container.</li>
  <li>Our reverse proxy server submits a POST request to the newly created container along with the <code class="highlighter-rouge">sessionURL</code> as the request body. The <code class="highlighter-rouge">sessionURL</code> is saved within a hash table to ensure there is no attempt to assign a <code class="highlighter-rouge">sessionURL</code> that is in use.</li>
  <li>We set up a heartbeat mechanism in our application server to continuously detect the number of connected clients. In any 10 seconds interval that no client is connected to our application server, it will submit a DELETE request to the <code class="highlighter-rouge">sessionURL</code>.</li>
  <li>Our reverse proxy receives the DELETE request and stops the container that is associated with the <code class="highlighter-rouge">sessionURL</code> to free up resources.</li>
  <li>The <code class="highlighter-rouge">sessionURL</code> is removed from the hash table.</li>
</ol>

<h1 id="7-benchmark-and-analysis">7 Benchmark and Analysis</h1>

<h2 id="71-streaming-vs-buffering-outputs">7.1 Streaming vs. Buffering Outputs</h2>
<p>A REPL program sends outputs in the form of chunks of data. For each evaluation, our application would receive several to many smaller chunks of output data.</p>

<p>To demonstrate this, let’s evaluate the code <code class="highlighter-rouge">[1,2,3].map(String)</code> on the Node.js REPL. We can reasonably expect the final output to be:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt; [1,2,3].map(String)
[ '1', '2', '3' ]
&gt;
</code></pre></div></div>

<p>However, since we are writing and reading data directly to and from a pseudoterminal, the evaluation result is written out through the standard output (a readable stream). This means that the first chunk of data available to be read from the readable stream may not contain our full output.</p>

<p>In fact, the chunks of output data from the same example above may look something like this:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[1      # first chunk of data
,2,3].  # second chunk of data
map     # third chunk and so on...
(St
ri
ng
)
\r\n
[ '1', '2', '3' ]\r\n
&gt;       # final chunk of data
</code></pre></div></div>

<h3 id="72-buffering-outputs">7.2 Buffering Outputs</h3>
<p>With this effect, it makes sense to concatenate all chunks before sending it as a complete response. This is known as <a href="http://web.archive.org/web/20101216035343/http://dev-tips.com/featured/output-buffering-for-web-developers-a-beginners-guide">output buffering</a>.</p>

<p>After buffering output, it would look something like:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[1,2,3].map(String)\r\n[ '1', '2', '3' ]\r\n&gt; 
</code></pre></div></div>

<p>The advantage to this in our use case is that we can easily parse out the current prompt depending on the current runtime (<code class="highlighter-rouge">&gt;</code> for Node.js, <code class="highlighter-rouge">irb(main):XXX:0&gt;</code> for Ruby and <code class="highlighter-rouge">&gt;&gt;&gt;</code> for Python) on the client-side. The prompt is useful for re-writing the entire terminal line when syncing with other clients.</p>

<p>Since chunks of data arrive in different intervals (around 1-4 ms in between), we would set a maximum wait time of 5 ms every time a new data chunk is received. If no new data is received within the 5 ms, we conclude that the output is finished and send the complete buffered output to the client.
The trade-off here is that the buffering costs additional wait time.</p>

<h3 id="73-streaming-outputs">7.3 Streaming Outputs</h3>
<p>Our initial approach of buffering outputs seem to work fine. Nonetheless, we found out that we could parse out the prompt on the server-side instead by caching the last chunk of data received. An example data chunk would be <code class="highlighter-rouge">=&gt; 123\r\nirb(main):003:0&gt; </code>, by caching this data chunk, we can easily parse out the <code class="highlighter-rouge">irb(main):003:0&gt; </code> prompt.
With this, it is no longer necessary to buffer outputs. Instead, we could stream the outputs as-is to the client. The benefit of this is that it not only removes any additional processing, but also simplifies our code logic by avoiding any use of <code class="highlighter-rouge">setTimeouts</code> or <code class="highlighter-rouge">setIntervals</code>.</p>

<p>With these two approaches in mind, we decided to run some benchmarking so that we can compare the performance between them. We utilized Artillery, a load testing toolkit to measure the performance of both approaches.</p>

<p>Our benchmarking setup involves connecting 20 virtual users one at a time to our server, with each submitting 5 evaluation requests, thereby totaling 100 requests per test.</p>

<p>The results show that streaming has a slightly lower latency, due to the fact that no wait time is necessary before sending the first output:</p>

<table>
  <thead>
    <tr>
      <th>Server Location</th>
      <th>Median Latency with Buffering Enabled (ms)</th>
      <th>Median Latency with Streaming (ms)</th>
      <th>Difference</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>localhost</td>
      <td>12.3</td>
      <td>2.1</td>
      <td>10.2</td>
    </tr>
    <tr>
      <td>remote, near (NYC to NYC)</td>
      <td>21.3</td>
      <td>15.2</td>
      <td>6.1</td>
    </tr>
    <tr>
      <td>remote, far (NYC to SF)</td>
      <td>89.3</td>
      <td>78.9</td>
      <td>10.4</td>
    </tr>
  </tbody>
</table>

<p>The results provide some perspectives on further optimizations that we can make. For example, if we require some heavy string processing on the client-side, then it make sense to employ the buffering approach since sacrificing a ~10 ms wait time would not be much of an issue. However, in our use case, we employ the streaming approach since it is acceptable to display output data to the client without any pre-processing. With this, we can reduce latency while simplifying our code logic.</p>

<h1 id="8-future-work">8 Future Work</h1>

<h2 id="81-improve-user-experiences">8.1 Improve User Experiences</h2>
<p>Currently, when multiple users write code in our text editor on the front-end there is no distinction between user cursors. This can make it difficult to see the location of all the cursors or to tell which cursor belongs to which user as they type. To improve the collaboration experience, we want to assign each cursor a unique color and name, similar to a small tooltip icon. This will make it easier to distinguish where each cursor is located in the editor and who is writing what.</p>

<h2 id="82-allow-code-upload-and-download">8.2 Allow Code Upload and Download</h2>
<p>There may be instances in which a user needs to leave their session but would like to download and save their code onto their local machine. Additionally, some users may have written code in their code editor and would like to upload it into their session of SpaceCraft. To accomodate these use cases, we’d like to add the ability for users to click a button and download the code from our text editor to be saved on their local machine. We’d also like to add a second button which upon being clicked will allow users to choose a file on their local machine and upload it’s contents into our text editor.</p>

<h2 id="83-support-low-level-languages">8.3 Support Low-Level Languages</h2>
<p>While SpaceCraft supports Ruby, JavaScript, and Python, we would like to expand our list of supported languages to include low-level languages like Rust, Go, Crystal, or C/C++. The process to support these languages will be more involved than higher-level languages since we will need to:</p>

<ul>
  <li>Take the user’s input and write it as a file in our backend.</li>
  <li>Have the low-level language runtime compile the code in the file and save the result as a separate file.</li>
  <li>Parse the contents of the result file and stream it as output to the user.</li>
  <li>Clean up our backend by deleting these generated files.</li>
</ul>

<p>This is process is a fair bit more complicated than how we’ve supported our current list of languages, and we’re excited to tackle the challenge to expand the capabilities of SpaceCraft!</p>

<h2 id="83-implement-a-request-queue">8.3 Implement a Request Queue</h2>
<p>Currently, our system architecture has a reverse proxy handling all user requests and forwarding them to the appropriate containers. However, we’ve noticed that when a large number of users submit a request at the same time, our reverse proxy can struggle to handle the load and fail.</p>

<p>To prevent this from occurring, we aim to implement a request queue which will take each HTTP request and store it until our reverse proxy is ready to handle the request. While this will reduce the load on our reverse proxy, our users will likely experience a greater latency between requesting to connect to our application and actually connecting to their container.</p>

<p>However, we believe this is an acceptable consequence since the part of our application with the greatest performance and lowest latency should be the actual REPL and editor. Once the user is connected to their container, the experienced latency for writing and evaluating code is significantly small with no noticeable lag.</p>

<h1 id="9-about-the-team">9 About the Team</h1>
<p>Our team of three software developers built SpaceCraft remotely, working together across the United States. Please feel free to contact us if you’d like to talk about software engineering, containers, or the web. We’re all open to learning about new opportunities!</p>

<!-- Place our pictures here with names, titles, location, and link to personal websites. -->

<h1 id="references">References</h1>
<p>If you’re interested in building your own REPL, learning about containers, or trying our WebSockets, we recommend that you checkout out the resources below. They have been invaluable to our research and development.</p>



      <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="http://github.com/spacecraft-repl/spacecraft-repl.github.io">spacecraft-repl.github.io</a> is maintained by <a href="http://github.com/spacecraft-repl">spacecraft-repl</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </section>

    
  </body>
</html>
